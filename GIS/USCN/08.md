# 可解释人工智能和地理学

## 0 可解释人工智能

+ 人工智能的普遍应用
+ 大模型
+ 准确度和可解释性之间的权衡：线性回归、决策树、SVM、集成方法、深度学习，可解释性$\arrow$，准确度$\arrow$
+ AI作为black box，及其存在的问题：e.g. 美国法院黑人再犯罪率的概率评价，简历自动筛查的性别歧视

Explainable artifcial intelligence (XAI) is a set of processes and methods that allows human users to comprehend and trust the results and output created by machine learning algorithms.

+ XAI解释图像：e.g. CNN卷积过程中的特征重要性评估
+ XAI解释文字：e.g. Google的
+ XAI解释表格：e.g. 随机森林的feature importance 和 Partial dependence plot 计算

推荐：[Interpretable Machine Learning: A Guide for Making Black Box Models Explainable](https://christophm.github.io/interpretable-ml-book/)

## 1 XAI的方法

基本方法：
+ 模型相关：关注模型的内部参数和结构
+ 模型无关（Post hoc）：不关注模型的内部参数和结构，只通过输入和输出判断二者关系和特征重要性

全局/局部解释：
+ Global: 对于所有样本/预测值的解释，e.g.全局特征重要性
+ Local: 对于每一个样本/预测值的解释，每一个个体决定是如何形成的，符合法律政策规定，e.g. GDPR’s "right to explanation"

典型方法：
1. LIME(Local Interpretable Model-agnostic Explanation, 2016)，复杂的非线性过程可以通过简单的局部线性关系所解释；局部随机取样本，根据距离进行加权，用黑盒模型进行预测，用简单模型进行解释；简单模型可以是决策树，线性回归等
2. Shapley value，源自博弈论，是公平分布的唯一满足下述属性解决方案：
+ Effciency: 每个玩家独立贡献总和等于所有玩家共同参与时的产出
+ Null:一个玩家没参与游戏那贡献为0
+ Symmetry:两个玩家贡献等同如果他们在所有的参与的游戏中产出相同+
+ Additivity:当有多个游戏时，一个玩家在每个游戏的贡献的总和是他在所有游戏中的贡献

Shapley值在机器学习中: 游戏 -> 模型, 玩家 -> 特征, 产出 -> 预测值

Shapley值计算是NP-Hard（组合穷举），Python包SHAP提供了一系列有效的Shapley值估算方法。

+ Lundberg & Lee.(2017). A unifed approach to interpreting model predictions.Advances in neural information processing systems, 30.
+ Lundberg, et al.(2020). From local explanations to global understandingwith explainable Al for trees. Nature machine intelligence, 2(1), 56-67.

## 2 XAI与地理学

**Space and place together define the nature of geography.——Yi-Fu Tuan**

+ 现象和行为在space和place的相似性和不同性，及底层原因
+ 个体，局部，全局-->地理尺度
+ 地理大数据，ESRI：80%的数据有地理维度

(X)AI: 对地理现象进行解释和模拟

一些XGeoAI的应用...

论文导读：Extracting spatial effects from machine learning model using localinterpretation method: An example of SHAP and XGBoost, Ziqi Li

1. 研究目的：
2. 实验设计：
 + 设计真正的空间过程（Data Generating Proces）：
   + 空间自回归效应（Spatial Lag）
   + 空间变化效应（MGWR）
 + 根据过程生成合成数据
 + 
 + XGBoost + SHAP
 + 位置与其他的交互效应
3. 结果比较
 + SLR
 + MGWR
 + 添加非线性关系后的
4. XAI将两个领域连接在一起：Spatial statistics models ----- XAI ---- ML/DL

## 3 机遇与挑战

1. OpenXAI(Agarwal, 2022): Data -> Model -> Prediction -> XAI -> Explanation：true to the model or true to the data? Ground truth faithfulness, prediction faithfulness, stability, etc.
2. 大数据大模型背景下的“大解释”：dimension reduction; 与地理知识的综合（降维至地点、空间、时间、尺度、背景、异质）; 交互式可视化

Q&A:
+ sparsity：根据SHAP值判断变量的有效性，使用XAI诊断数据变量
+ 多值输出的可解释性：如路段交通流量的时空预测，输出为一个graph -> 可以对解释结果的参数值做聚类或对研究单元做generalization
+ 如何保证解释结果是真实的因果关系，输入变量不足时对其他解释变量的解释，如单纯使用历史数据预测交通流量 -> 如使用历史数据时流量结果已经是对其他结果的反应，可以对单样本进行解释，这种情况下全局解释捕获到的只能从输入数据中获取，correlation 和 causality 之间的关系
+ 因果关系和XAI的关系，LIME和SHAP值都可以纳入因果关系的框架之下
