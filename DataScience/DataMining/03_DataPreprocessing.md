# 03 数据预处理

## 3.1 概述

### 3.1.1 数据质量

+ 准确性（accuracy）：正确反映对象的属性，不包含或很少包含噪声或异常值
+ 完整性（completeness）：属性值完整，属性项满足分析需求
+ 一致性（consistency）：多种数据源对同一对象的属性值应当一致
+ 时效性（timeliness）：也就是现势性
+ 可信性（believability）：反映有多少数据是用户信赖的
+ 可解释性（interpretability）：反映数据是否易理解

### 3.1.2 数据预处理的主要任务

+ 数据清理：通过填写缺失值、光滑噪声数据、识别或删除离群点，并解决不一致性来“清理”数据
+ 数据集成：集成多个数据库、数据立方体或文件，并采取措施避免数据集成时的冗余和不一致，这有利于提高后续数据挖掘的准确性和速度
+ 数据归约：在实现（几乎）同样分析效果的前提下简化数据集的表示，分为维归约（dimensionally reduction）和数值归约（numerosity reduction）两类归约方法。维归约使用数据编码方案，得到原始数据的简化/压缩表示，包括数据压缩技术（如小波变换、主成分分析）、属性子集选择（去除与分析过程不相关的属性）和属性构造（从原来的属性集导出更有用的小属性集）；数值规约使用参数模型（如回归）或非参数模型（如聚类、抽样、数据聚合），用规模更小的表示取代原始数据。
+ 数据变换：如规范化（Normalization）、离散化（Discretization）和概念分层（Concept Hierarchy Generation）

## 3.2 数据清理（Data Cleaning）

### 3.2.1 缺失值

|处理方法|描述|
|:----:|:----:|
|忽略tuple|适合缺失属性值较多的情况，或缺少类别属性（如果需要用到这个属性）的情况|
|人工填写缺失值|费时，数据集较大时这种方法是不现实的|
|使用全局常量填充缺失值|简单，但可能被挖掘算法误识别，从而使分析结果不太可靠|
|使用属性的中心度量（如均值或中位数）填充缺失值|正态数据适合使用中位数，偏态数据适合使用中位数|
|使用与给定tuple同一类所有样本的中心度量（如均值或中位数）||
|使用最可能的值填充缺失值|如使用回归、决策树、贝叶斯等方法进行推测|

说明：

+ 后四种方法使数据变得有偏，因为填入的值可能不符合实际情况，最后一种方法是最popular的策略，因为它最大程度地利用了已知的数据；
+ 缺失值不一定意味着数据有错误，因为在某些情况下空值是允许的，理想情况下，每个属性都应当有关于空值条件的规则。

### 3.2.2 数据噪声

噪声（noise）是被观测的变量的随机误差或方差，对于噪声的处理有如下几种方法：

|方法|描述|
|:----:|:----:|
|分箱（binning）|一种局部光滑策略，首先将数据排序，然后划分至一定数目“箱”之中（也就是分成若干组），最后使用不同的策略进行光滑（箱均值/箱中位数/箱边界）|
|回归（regression）|用一个函数的拟合数据来光华数据|
|离群点分析（outlier analysis）|通过聚类等方法将离群点检测出来|

许多数据光滑的方法也用于数据离散化和数据归约。

### 3.2.3 数据清理的过程

+ 偏差检测（discrepancy detection）
  + 获取数据的元数据（metadata）知识，如每个属性的类型和值域
  + 使用描述性统计量通过某种规则进行检测
+ 注意编码的不一致和数据表达方式的不一致（如日期的不同表达）
+ 注意字段过载（field overloading）问题
+ 还可以根据以下原则考察数据：
  + 唯一性原则：某些情况下可能要求每个数据对象的某属性值必须与其他对象的该属性值不同；
  + 连续性原则：某些情况下可能要求某属性的最低值和最高值之间没有缺失的值，且值唯一；
  + 空值原则：是否使用特殊符号来指示空值
+ 数据清理工具的类别
  + 数据清洗工具（data scrubbing tool）
  + 数据审计工具（data auditing tool）
  + 数据迁移工具（data migration tool）
  + 数据变换操作的规范说明语言

## 3.3 数据集成（Data Integration）

### 3.3.1 实体识别问题（Entity Identification Problem）

模式集成（Schema Integration）或对象匹配（Object Matching）时不可避免地会涉及到Entity Identification，如两张表中的两个字段是否表示同一种属性的判断，再如两张表中对同一属性相同类别量的不同表达，匹配过程应当注意维持数据的结构，如参照约束和函数依赖的保持。

### 3.3.2 冗余和相关分析（Redundancy and Correlation Analysis）

一个属性如果能由其他属性导出或表中存在着与其表达性质相同但属性名字不同的属性，那么这张表存在冗余。

冗余可以由相关性分析检测，对于名义属性，可以使用$$\chi^2$$检验，对于其他属性，可以使用相关系数和协方差评估。

|统计量|参数说明|说明|
|:----:|:----:|:----:|
|$$\chi^2=\sum_{i=1}^{c}{\sum_{j=1}^r{\frac{(o_{ij}-e_{ij})^2}{e_{ij}}}}$$|A由c个值组成，B由r个值组成，令($$A_i,B_j$$)表示属性$$A$$取$$a_i$$属性$$B$$取$$b_j$$的联合事件，$$o_{ij}是联合事件(A_i,B_j)$$的观测频度（即实际计数），$$e_{ij}$$是$$(A_i,B_j)$$的期望，$$e_{ij}=\frac{count(A=a_i)\cdot{count(B=b_j})}{n}$$，其中n是数据tuple的个数|计算出$$\chi^2$$后再根据置信度水平和拒绝域进行判断是否相关（原假设是两个属性独立）|
|$$PPMCC=r_{A,B}=\frac{\sum_{i=1}^n{(a_i-\overline{A})(b_i-\overline{B})}}{n\sigma_A\sigma_B}=\frac{\sum_{i=1}^n{a_ib_i}-n\overline{A}\overline{B}}{n\sigma_A\sigma_B}$$||也就是我们熟悉的皮尔逊相关系数，值域为\[-1,1\]，实际上相关系数不只有PPMCC一种，还有如Kendall相关系数、Spearman相关系数（都适用于次序属性），计算出相关系数后也是需要进一步进行显著性检验的|
|$$Cov(A,B)=E((A-\overline{A})(B-\overline{B}))=E(AB)-E(A)E(B)=\frac{\sum_{i=1}^n{(a_i-\overline{A})(b_i-\overline{B}))}}{n}$$||$$r_{A,B}=\frac{Cov(A,B)}{\sigma_A\sigma_B}$$，协方差为正则说明正相关，为负则说明负相关，独立属性的协方差为0，但是其逆不成立，无须显著性检验|

### 3.3.3 元组重复（Tuple Duplication）

当在给定唯一数据约束的前提的数据表中存在着完全相同的数据对象时，需要将多余的对象删除。

### 3.3.4 数据值冲突的检测预处理

即数据不一致的检测处理，需要对其进行变换以使之在同一种表示/尺度/编码下。

## 3.4 数据归约（Data Reduction）

数据归约技术可以用来得到数据集的归约表示，其规模比原数据小得多，但仍然保持原始数据的完整性，在规约后的数据上进行挖掘将更有效，同时产生几乎一致的挖掘效果。

### 3.4.1 概述

|归约方法|概述|
|:----:|:----|
|维归约（dimensionality reduction）|减少随机变量或属性的个数，主要包括小波变换和主成分分析（将原始属性变换或投影到另一个维度较少的空间），属性子集选择也是一种维归约方法，即检测删除不相关、弱相关或冗余的属性|
|数量归约（numerosity reduction）|用较小规模的数据去替代原数据，包括参数方法（使用模型估计数据，则只需要存储模型参数，如回归模型）和非参数方法（如直方图、聚类、抽样和数据立方体聚合（data cube aggregation））|
|数据压缩（data compression）|使用某种变换方法，得到原数据的归约或压缩表示，分为有损压缩和无损压缩，前两种方式也可以视作数据压缩|

### 3.4.2 离散小波变换 DWT, Discrete Wavelet Transformation

小波变换前后的数据长度相等，但是我们可以通过截短方式仅保留一部分最强的小波系数，使低于阈值的部分全置为0，这样变换后的向量就变得很稀疏，从而达到归约的效果。可以利用这种变换消除噪声、保留主要特征。

一般而言，DWT比DFT（Discrete Fourier Transformation，离散傅里叶变换）效果更好。

具体数学原理不再介绍。

### 3.4.3 主成分分析 PCA, Priciple Component Analysis

即搜索k个最能代表数据的n维正交向量，k≤n。PCA通过创建维度更小的组合属性集，原数据投影到该属性空间中，从而实现“维归约”的效果。

其基本过程：

1. 规范化输入数据
2. 计算协方差矩阵（将变量规范化后再计算得到的协方差阵实质上就是其属性间的相关系数阵）
3. 求协方差阵的特征值$$\lambda_i$$及相应的正交化单位特征向量$$\alpha_i$$，$$\lambda_i$$的前$$m$$个较大的特征值就是其主成分对应的方差，主成分信息贡献率$$a_i=\frac{\lambda_i}{\sum_{i=1}^m{\lambda_i}}$$
4. 选择主成分，当前m个主成分的累计方差贡献率大于80%时，认为足够反映原来变量的信息，取这前m个主成分
5. 计算主成分载荷，主成分载荷反映的是主成分$$F_i=\alpha_iX$$与原变量之间的关联程度，若原变量$$X_j$$在各个主成分$$F_i$$上的载荷为$$l_{ij}$$，则$$l_{ij}=\sqrt{\lambda_i}\alpha_{ij}$$
6. 计算主成分得分，计算样品在m个主成分上的得分：$$F_i=l_{1i}X_1+l_{2i}X_2+...+l_{pi}X_p, i=1,2,...,m$$

主成分可以用做多元回归和聚类分析的输入，与小波变换相比，PCA可以更好地处理系数数据，而小波变换更适合处理高维数据。

### 3.4.4 属性子集选择

通过删除不相关、弱相关或冗余的属性来减少原数据的维度，其目标是找出最小的属性集，使得数据类的概率分布尽可能地接近所使用的所有属性的原分布。通常使用压缩搜索空间的启发式算法进行属性的选择，本质上就是一种贪心算法，通过寻找局部最优来逼近全局最优，通常有以下几种方式：

|选择方法|说明|
|:----:|:----|
|向前逐步选择|归约集由空集开始，逐步添加原属性集中最优的属性到归约集|
|向后逐步删除|归约集由原属性集开始，逐步删除其中最差的属性|
|逐步向前选择和逐步向后删除相结合||
|决策树归纳|构造决策树，出现在决策树中的属性集合作为归约集|

还可以基于原属性构造新属性，如基于长和宽构造面积。

### 3.4.5 回归和对数线性模型：参数化数据归约

### 3.4.6 直方图 Histogram

### 3.4.7 聚类

简而言之就是把数据元组视作对象，聚类算法将这些对象划分为群或簇，簇内对象相似，簇外对象相异。

### 3.4.8 抽样

假设数据集D中有N个元组，不同的抽样方式如下所示：

|抽样方式|描述|
|:----:|:----|
|无放回简单随机抽样|SRSWOR，Simple Random Sample Without Replacement|
|有放回简单随机抽样|SRSWR，Simple Random Sample With Replacement|
|簇抽样|Cluster Sample，D中数据被分组放入M个互不相交的簇中（这里的簇间差异小，簇内差异大），抽样时随机抽取一个或多个簇即可|
|分层抽样|Stratified Sample，D中数据按某一或某些属性被分入若干个不同的组中，对每一个组内数据按一定比例进行简单随机抽样|

可以使用中心极限定理在一定的误差范围内估计抽样的样本大小。

### 3.4.9 数据立方体聚类

立方体的每个单元存放一个聚类值，对应于多维空间的一个数据点，每个属性都可能存在概念分层，允许在多个抽象层进行数据分析。在最低层创建的立方体称为基本立方体（base cuboid），最高层抽的立方体被称为顶点方体（apex cuboid），更高层抽象都可以减小更低层抽象的数据规模。

## 3.5 数据变换和数据离散化（Data Transformation and Data Discretization）

### 3.5.1 相关概念

|名称|介绍|
|:----:|:----|
|光滑|去除数据中的噪声|
|属性构造||
|聚集（Aggregation）|对数据进行汇总|
|规范化（Normalization）|将数据按比例缩放，使之落入一个固定区间|
|离散化|数值属性的原始值用区间标签（如1-10）或概念标签（如"youth"）替换，即对数据进行概念分层（分组）|
|由标签数据产生概念分层||

### 3.5.2 规范化

使用规范化可以消除量纲的影响，避免对度量单位选择的依赖性。如规范化属性A的各种规范化方法如下所示：

|方法|公式|说明|
|:----:|:----:|:----|
|最大-最小规范化|$$v_i^{'}=\frac{v_i-min_A}{max_A-min_A}(new_max_A-new_min_A)+new_min_A$$||
|z-分数规范化|$$v_i^{'}=\frac{v_i-\overline{A}}{\sigma_A}$$|也称零均值规范化，$$\overline{A}、\sigma_A$$分别是属性A的均值和标准差|
|小数定标标准化|$$v_i^{'}=\frac{v_i}{10^j}$$|j是使$$max{|v_i|}≤1$$成立的最小整数|

### 3.5.3 通过分箱离散化

指定箱的个数，自顶向下进行分裂，再使用箱均值或箱中位数等方法替换箱中的每个值。

### 3.5.4 通过直方图分析离散化

直方图把属性A的值划分为不相交的区间，可以递归地再对每个区间划分，在最小区间长度的约束下德奥预先设定的区间数。

### 3.5.5 通过聚类、决策树和相关性离散化

聚类和决策树是自顶向下的，相关性度量是自底向上的（递归地找出邻近的区间（借助$$\chi^2$$检验），然后合并之，称作ChiMerge过程）。

### 3.5.6 标称数据的概念分层产生

主要就是通过专家或用户在模式级显式地说明属性的顺序，或通过显式地数据分组说明分层结构的一部分。
